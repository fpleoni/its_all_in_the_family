{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from random import choice, sample\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Lambda, Dense, Flatten,MaxPooling2D,Activation, Dropout, BatchNormalization,  GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Subtract,Multiply\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from skimage.io import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# from glob import glob\n",
    "# from random import choice, sample\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "# from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "# from keras.layers import Input, Dense, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract\n",
    "# from keras.models import Model\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# # File paths\n",
    "# train_file_path = \"../data/train/\"\n",
    "# train_relationships_path = \"../csv_files/train_relationships.csv\"\n",
    "# validation_path = \"F09\"\n",
    "\n",
    "# all_images = glob(train_folders_path + \"*/*/*.jpg\")\n",
    "\n",
    "# train_images = [x for x in all_images if val_famillies not in x]\n",
    "# val_images = [x for x in all_images if val_famillies in x]\n",
    "\n",
    "# train_person_to_images_map = defaultdict(list)\n",
    "\n",
    "# ppl = [x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2] for x in all_images]\n",
    "\n",
    "# for x in train_images:\n",
    "#     train_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n",
    "\n",
    "# val_person_to_images_map = defaultdict(list)\n",
    "\n",
    "# for x in val_images:\n",
    "#     val_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "train_file_path = \"train/\"\n",
    "train_relationships_path = \"train_relationships.csv\"\n",
    "#the validation set will be family members F09...\n",
    "validation_set = \"F09\"\n",
    "\n",
    "#get all the images\n",
    "all_images = glob(train_file_path + \"*/*/*.jpg\")\n",
    "\n",
    "#seperate the train and validation sets\n",
    "train_images = [img for img in all_images if validation_set not in img]\n",
    "val_images = [img for img in all_images if validation_set in img]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary with key=family member and value=list of pictures of family member\n",
    "def fam_mem_pics(all_images):\n",
    "    #create dictionary\n",
    "    fam_member_dict = {}\n",
    "    #create list for member pictures\n",
    "    fam_member_lst = []\n",
    "    i = 0\n",
    "    while i < len(all_images)-1:\n",
    "        #get the family member as key\n",
    "        key = all_images[i][6:16]\n",
    "        #check if picture is about the same fmaily member\n",
    "        same_member = True\n",
    "\n",
    "        while same_member:\n",
    "            #check if same family member\n",
    "            if key in all_images[i]:\n",
    "                #append the image to the family member list\n",
    "                fam_member_lst.append(all_images[i])\n",
    "                \n",
    "            else:\n",
    "                #changed family member\n",
    "                same_member = False\n",
    "            \n",
    "            #update the counter to not go out of bounds\n",
    "            if (i+1) < len(all_images):  \n",
    "                i += 1\n",
    "            else:\n",
    "                #break if out of bounds\n",
    "                break\n",
    "            \n",
    "        #create key=family member and value= list of family member's pictures\n",
    "        fam_member_dict[key] = fam_member_lst\n",
    "        fam_member_lst = []\n",
    "        \n",
    "    #return the member_dictionary \n",
    "    return fam_member_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a family member image dictionary\n",
    "map_train_person_to_images = fam_mem_pics(train_images)\n",
    "map_val_person_to_images = fam_mem_pics(val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_val_person_to_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the raltionships dataframe\n",
    "df = pd.read_csv(\"train_relationships.csv\")\n",
    "\n",
    "#get isolate the the family/member portions to compare\n",
    "all_family_members = [img[6:16] for img in all_images]\n",
    "\n",
    "#some relationships are not present within the relationship csv\n",
    "#remove them by only keeping the ones mentioned in the dataset\n",
    "df = df[df['p1'].isin(all_family_members)]\n",
    "df = df[df['p2'].isin(all_family_members)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate the training and validation labels\n",
    "train = df[~df['p1'].str.contains(validation_set)]\n",
    "val = df[df['p1'].str.contains(validation_set)]\n",
    "\n",
    "#turn dataframes to tuples to get labels\n",
    "train = list(zip(train['p1'].values, train['p2'].values))\n",
    "val = list(zip(val['p1'].values, val['p2'].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_person_to_images_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_family_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    return preprocess_input(img)\n",
    "\n",
    "\n",
    "def gen(list_tuples, person_to_images_map, batch_size=16):\n",
    "    ppl = list(person_to_images_map.keys())\n",
    "    while True:\n",
    "        batch_tuples = sample(list_tuples, batch_size // 2)\n",
    "        labels = [1] * len(batch_tuples)\n",
    "        print(batch_tuples)\n",
    "        print(labels)\n",
    "        while len(batch_tuples) < batch_size:\n",
    "            p1 = choice(ppl)\n",
    "            p2 = choice(ppl)\n",
    "            print('p1: ', p1)\n",
    "            print('p2: ', p2)\n",
    "            if p1 != p2 and (p1, p2) not in list_tuples and (p2, p1) not in list_tuples:\n",
    "                batch_tuples.append((p1, p2))\n",
    "                labels.append(0)\n",
    "        print(batch_tuples)\n",
    "        print(labels)\n",
    "        for x in batch_tuples:\n",
    "            print('x:, ', x)\n",
    "            if not len(person_to_images_map[x[0]]):\n",
    "                print('x[0]:, ', x)\n",
    "                print(x[0])\n",
    "        print('------------------------')\n",
    "        X1 = [choice(person_to_images_map[x[0]]) for x in batch_tuples]\n",
    "        X1 = np.array([read_img(x) for x in X1])\n",
    "\n",
    "        X2 = [choice(person_to_images_map[x[1]]) for x in batch_tuples]\n",
    "        X2 = np.array([read_img(x) for x in X2])\n",
    "\n",
    "#         yield [X1, X2], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen(train, train_person_to_images_map, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen(train, train_person_to_images_map, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(list_tuples, person_to_images_map, batch_size=16):\n",
    "    ppl = list(person_to_images_map.keys())\n",
    "    while True:\n",
    "        batch_tuples = sample(list_tuples, batch_size // 2)\n",
    "        labels = [1] * len(batch_tuples)\n",
    "        while len(batch_tuples) < batch_size:\n",
    "            p1 = choice(ppl)\n",
    "            p2 = choice(ppl)\n",
    "\n",
    "            if p1 != p2 and (p1, p2) not in list_tuples and (p2, p1) not in list_tuples:\n",
    "                batch_tuples.append((p1, p2))\n",
    "                labels.append(0)\n",
    "\n",
    "        for x in batch_tuples:\n",
    "            if not len(person_to_images_map[x[0]]):\n",
    "                print(x[0])\n",
    "\n",
    "        X1 = [choice(person_to_images_map[x[0]]) for x in batch_tuples]\n",
    "        X1 = np.array([read_img(x) for x in X1])\n",
    "\n",
    "        X2 = [choice(person_to_images_map[x[1]]) for x in batch_tuples]\n",
    "        X2 = np.array([read_img(x) for x in X2])\n",
    "        \n",
    "        print(X1)\n",
    "        \n",
    "        yield [X1, X2], labels\n",
    "        \n",
    "gen(train, train_person_to_images_map, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_relationships.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_path = \"train/\"\n",
    "\n",
    "families = os.listdir(train_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_path = \"train/\"\n",
    "\n",
    "for i in range(len(os.listdir(train_path)[:1])): #len(os.listdir(train_path))\n",
    "    print(df.iloc[0])\n",
    "    \n",
    "    member_1 = os.listdir(train_path + str(df.iloc[0]['p1']))\n",
    "    member_2 = os.listdir(train_path + str(df.iloc[0]['p2']))\n",
    "    \n",
    "    for member_pic in member_1\n",
    "    \n",
    "    print('-----------')\n",
    "    print(member_1)\n",
    "    print(member_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in member_1:\n",
    "    try:  \n",
    "        img  = Image.open('train/F0002/MID1/P00016_face2.jpg')  \n",
    "    except:\n",
    "        print('not work')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_member_1_face = np.random.randint(low=0, high=len(member_1))\n",
    "random_member_2_face = np.random.randint(low=0, high=len(member_2))\n",
    "\n",
    "print(random_member_1_face)\n",
    "print(random_member_2_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for face in member_1:\n",
    "    \n",
    "    filename = face\n",
    "    print(filename)\n",
    "#     img = image.load_img(filename, target_size=(150, 150))\n",
    "# #     plt.imshow(img)\n",
    "# #     plt.show()\n",
    "\n",
    "#     img_tensor = image.img_to_array(img)\n",
    "#     img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "\n",
    "#     #Follow the Original Model Preprocessing\n",
    "#     img_tensor /= 255.\n",
    "\n",
    "#     #Check tensor shape\n",
    "#     print(img_tensor.shape)\n",
    "\n",
    "#     #Preview an image\n",
    "#     plt.imshow(img_tensor[0])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir = 'train'\n",
    "# validation_dir = 'data_org/val/'\n",
    "test_dir = 'test'\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "size = 255\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(size, size),\n",
    "        color_mode=\"rgb\"\n",
    "        batch_size=20,\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(size, size),\n",
    "        color_mode=\"rgb\"\n",
    "        batch_size=20,\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_generator)\n",
    "val_images, val_labels = next(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape)\n",
    "print(val_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_labels.shape)\n",
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "print(train_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "cnn_base = VGG19(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(size, size, 3))\n",
    "\n",
    "cnn_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.Sequential()\n",
    "# model.add(cnn_base)\n",
    "# model.add(layers.Flatten())\n",
    "# # model.add(layers.Dense(64, activation='relu'))\n",
    "# # model.add(layers.Dense(128, activation='relu'))\n",
    "# # model.add(layers.Dense(128, activation='relu'))\n",
    "# model.add(layers.Dense(120, activation='sigmoid'))\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(255, 255,  3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
