{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-760b0d80fbf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mglob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "train_file_path = \"/Users/florencialeoni/code/its_all_in_the_family/data/train\"\n",
    "train_relationships_path = \"/Users/florencialeoni/code/its_all_in_the_family/csv_files/train_relationships.csv\"\n",
    "validation_path = \"F08\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions by Youness Mansar https://github.com/CVxTz/kinship_prediction\n",
    "all_images = glob(train_folders_path + \"*/*/*.jpg\")\n",
    "\n",
    "train_images = [x for x in all_images if val_famillies not in x]\n",
    "val_images = [x for x in all_images if val_famillies in x]\n",
    "\n",
    "train_person_to_images_map = defaultdict(list)\n",
    "\n",
    "ppl = [x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2] for x in all_images]\n",
    "\n",
    "for x in train_images:\n",
    "    train_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n",
    "\n",
    "val_person_to_images_map = defaultdict(list)\n",
    "\n",
    "for x in val_images:\n",
    "    val_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n",
    "\n",
    "relationships = pd.read_csv(train_file_path)\n",
    "relationships = list(zip(relationships.p1.values, relationships.p2.values))\n",
    "relationships = [x for x in relationships if x[0] in ppl and x[1] in ppl]\n",
    "\n",
    "train = [x for x in relationships if val_famillies not in x[0]]\n",
    "val = [x for x in relationships if val_famillies in x[0]]\n",
    "\n",
    "\n",
    "def read_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    return preprocess_input(img)\n",
    "\n",
    "\n",
    "def gen(list_tuples, person_to_images_map, batch_size=16):\n",
    "    ppl = list(person_to_images_map.keys())\n",
    "    while True:\n",
    "        batch_tuples = sample(list_tuples, batch_size // 2)\n",
    "        labels = [1] * len(batch_tuples)\n",
    "        while len(batch_tuples) < batch_size:\n",
    "            p1 = choice(ppl)\n",
    "            p2 = choice(ppl)\n",
    "\n",
    "            if p1 != p2 and (p1, p2) not in list_tuples and (p2, p1) not in list_tuples:\n",
    "                batch_tuples.append((p1, p2))\n",
    "                labels.append(0)\n",
    "\n",
    "        for x in batch_tuples:\n",
    "            if not len(person_to_images_map[x[0]]):\n",
    "                print(x[0])\n",
    "\n",
    "        X1 = [choice(person_to_images_map[x[0]]) for x in batch_tuples]\n",
    "        X1 = np.array([read_img(x) for x in X1])\n",
    "\n",
    "        X2 = [choice(person_to_images_map[x[1]]) for x in batch_tuples]\n",
    "        X2 = np.array([read_img(x) for x in X2])\n",
    "\n",
    "        yield [X1, X2], labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
